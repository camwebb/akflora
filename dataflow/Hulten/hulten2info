#!/usr/bin/gawk -f

# Images in hulten are 4510 wide x 6590 high

@include "/home/cam/desk/projects/taxon-tools/share/taxon-tools.awk"

BEGIN{
  
  DEBUG = 0
  Img     = 0       # image number counter
  pad     = 10      # padding pixels to add to image
  
  # Check arguments
  #if ((ARGC == 1) || (ARGV[ARGC-1] !~ /^[0-9]+$/)) {
  if (ARGC == 1) {
    print "Usage: hulten2info ... <page>" > "/dev/stderr"
    exit 1
  }
  
  Page    = ARGV[ARGC-1] # page number in book
  Page3   = sprintf("%03d",Page)
  Imgfile = "tiff/" Page3 "/" Page3 ".tiff" 

  if (ARGV[1] == "--tes") {

    while (("ls tiff/" Page3 "/*t.tiff" | getline) > 0) {
      print "OCRing " $1 
      system("tesseract " $1 " "  \
             gensub(/\.tiff$/,"","G", $1)       \
             " --user-words gen+sp_list ; "\
             "sed -i -E -e 's/[|^\\f]//g' -e '1{s/^[0-9]*\\.? +//g}' " \
             gensub(/\.tiff$/,".txt","G", $1))
      print "---------------------------------------------------------------"
      system("cat " gensub(/\.tiff$/,".txt","G", $1))
      print "---------------------------------------------------------------"
      system("emacs -nw -Q " gensub(/\.tiff$/,".txt","G", $1))
    }
    exit 0
  }

  else if (ARGV[1] == "--col") {
    # collect the OCR text
    collect()
    exit 0
  }

  else if (ARGV[1] == "--checkfields") {
    checkfields()
    exit 0
  }

  else if (ARGV[1] != "--nop") {  # no page
    
    # extract the image from the PDF
    export(Page)
    # View the main image
    # system("display -resize x1000 " Imgfile " &")
    
    if (ARGV[1] == "--pgo")  # page only
      # extract image only
      exit 0
  }
  
  # 1. first pass, slicing off the top 450 page header,
  #   and a bit of the bottom, scanning by rows
  # tweak                450 or 470
  chunkup(4510, 6000, 0, 470, Imgfile, 2, 100, 1)
  # returns an array Chunk with n chunks: starting row and length of rows
  
  # 1b. for each horizontal chunk, divide text from illustrations
  for (i in Chunk["len"]) { 
    # <--- 3050 text ---><--- 1460 ill --->    sum=4510
    # opt: two = 3050 ; twe = 3000
    two = 3050 ; twe = 2950
    # odd page
    if ((Page/2) != int(Page/2)) {
      # text
      W[++Img] = two     ;  H[Img] = Chunk["len"][i] + 2*pad
      X[Img]   = 0       ;  Y[Img] = Chunk["beg"][i] -   pad
      N[Img]   =            Page3 "-" i "-T.tiff"
      B[Img]   = i
      # illustration
      W[++Img] = 4510-two;  H[Img] = Chunk["len"][i] + 2*pad
      X[Img]   = two     ;  Y[Img] = Chunk["beg"][i] -   pad
      N[Img]   =            Page3 "-" i "-I.tiff"
      B[Img]   = i
    }
    else {
      # even page
      # text
      W[++Img] = twe     ;  H[Img] = Chunk["len"][i] + 2*pad
      X[Img]   = 4510-twe;  Y[Img] = Chunk["beg"][i] -   pad
      N[Img]   =            Page3 "-" i "-T.tiff"
      B[Img]   = i
      # illustration
      W[++Img] = 4510-twe;  H[Img] = Chunk["len"][i] + 2*pad
      X[Img]   = 0       ;  Y[Img] = Chunk["beg"][i] -   pad
      N[Img]   =            Page3 "-" i "-I.tiff"
      B[Img]   = i
    }
  }

  # 2. second pass, slicing off the maps
  for (i in W) {
    if (N[i] ~ /-T\./) {
      # already padded in (1) above
      chunkup(W[i], H[i], X[i], Y[i], Imgfile, 2, 80, 1)
      # assume 2 parts: maps and all else
      W[++Img] = W[i]      ;  H[Img] = Chunk["len"][1] + 2*pad
      X[Img]   = X[i]      ;  Y[Img] = Chunk["beg"][1] -   pad
      N[Img]   =              Page3 "-" B[i] "-m.tiff"
      B[Img]   = B[i]
      # the text, may be 1 or more bits
      for (j in Chunk["len"]) maxj = j 
      W[++Img] = W[i]      ;  H[Img] = Chunk["end"][maxj] - Chunk["beg"][2] \
                                + 2*pad
      X[Img]   = X[i]      ;  Y[Img] = Chunk["beg"][2] -   pad
      N[Img]   =              Page3 "-" B[i] "-t.tiff"
      B[Img]   = B[i]
    }
  }
  
  # third pass, slicing up the maps, vertically
  for (i in W) {
    if (N[i] ~ /-m\./) {
      # play with this thresh value:                   v
      chunkup(W[i], H[i], X[i], Y[i], Imgfile, 1, 300, 3)
      # assume 2: map 1 ; add no padding
      W[++Img] = Chunk["len"][1] ;  H[Img]   = H[i]
      X[Img]   = Chunk["beg"][1] ;  Y[Img]   = Y[i]
      N[Img]   =                    Page3 "-" B[i] "-1.tiff"
      # map 2
      for (j in Chunk["len"]) maxj = j 
      W[++Img] = Chunk["end"][maxj] - Chunk["beg"][2]
      H[Img]   = H[i]
      X[Img]   = Chunk["beg"][2] ;  Y[Img]   = Y[i]
      N[Img]   =                    Page3 "-" B[i] "-2.tiff"
    }
  }

  if (DEBUG) printf "%4s  %4s  %4s  %4s  %s\n", "W", "H", "X", "Y", "name"
  for (i in W) {
    if (DEBUG) {
      # view in print:
      printf "%4d  %4d  %4d  %4d  %s\n", W[i], H[i], X[i], Y[i], N[i]
      view in display
      system("display -crop " W[i] "x" H[i] "+" X[i] "+" Y[i]   \
             " -resize 500x500 -title " N[i] " " Imgfile " &")
    }
    else {
      # make subfiles
      if (N[i] ~ /-[It]\./)
        system("cd tiff/" Page3 " ; convert " \
               Page3 ".tiff -crop " \
               W[i] "x" H[i] "+" X[i] "+" Y[i] " " N[i] )
      if (N[i] ~ /-[12]\./)
        system("cd tiff/" Page3 " ; convert " \
               Page3 ".tiff -crop " \
               W[i] "x" H[i] "+" X[i] "+" Y[i] \
               " -fuzz 50% -trim " N[i])
    }
  }
  
  exit 1
}

function export(page,     paper){
  paper = paperpage(page)
  print "... extracting book page " page " (pdf page " paper ")" \
    > "/dev/stderr"
  system("cd tiff ; mkdir " sprintf("%03d",page) " ; cd " sprintf("%03d",page) \
         "; pdfimages -tiff -f " paper " -l " paper \
         " ../../hulten.pdf tmp ; mv tmp-000.tif " sprintf("%03d",page) \
         ".tiff ; rm -f tmp*")
  # test for size
  cmd = "identify tiff/" sprintf("%03d",page) "/" sprintf("%03d",page) \
         ".tiff"
  cmd | getline size
  if (substr(size, 24, 4) != "4510") {
    print "Warning, page is not 4510 pixels wide. Expanding..." > "/dev/stderr"
    system("cd tiff/" sprintf("%03d",page) " ; convert " sprintf("%03d",page) \
           ".tiff -resize 4510x " sprintf("%03d",page) ".tiff")
  }
  # normal size: 4510x6590
  # normal alignment of header divider:
  #   Length : ~3930; To top: ~395; To outer edge: ~470; to spine: ~100
  # In GIMP: expand %, crop to 4510x6590, shift (using measure),
  #   add white layer to fill in gaps, flatten, overwrite
}


function chunkup(w, h, x, y, infile, orient, dim, thres                   \
                 , cmd, c, bn, j, i, bot, pad, top, hgt, dimt) {
  
  # orient=2: scan for horiz gaps; orient=1: scan for vert gaps
  if      (orient == 2) dimt =     "x" dim
  else if (orient == 1) dimt = dim "x"
  
  # resize to ~1/60 size, this blurs the content, but maintains the major
  # (but not inter-line) spaces.
  cmd = "convert " infile " -crop " w "x" h "+" x "+" y \
    " -resize " dimt " -threshold 97% -depth 1 txt:-"
  # if (dim==80) # print cmd
  #   system("display -crop " w "x" h "+" x "+" y                         \
  #        " -resize " dim "x" dim " -threshold 97% -depth 1 tiff/" infile " & ") 
  while ((cmd | getline) > 0 ) {
    gsub(/:/,"",$1)
    # only lines that have coordinates
    if ($1 ~ ",") {
      split($1,c,",")  # coordinates are xpix, ypix
      if ($3 == "#000000") bn[c[orient]]++
    }
  }

  # n > thres  -> row is black ; test on p112
  bn[-1] = 0 # coordinates numbered from 0, line beyond top is white
  j = 0
  for (i = 0; i < dim; i++) {
    if (!bn[i]) bn[i] = 0
    # black
    if (bn[i] > thres) {
      # change to black
      if (bn[i-1] <= thres) {
        # new band
        j++
        top[j] = i
      }
    }
    else {
      # change to white
      if (bn[i-1] > thres) {
        # new band
        bot[j] = i
      }
    }
  }  

  # end black band if last line was black 
  if (!bot[j]) bot[j] = dim

  if (orient == 1) {
    h = w # if scanning vertically, the longest dim is width
    y = x #                         and we add the x, not y
  }

  if (isarray(Chunk)) delete Chunk  # clear array if exists
  # for each band
  for (i in top) {
    Chunk["len"][i] =  int(    (bot[i]- top[i]) * (h / dim))   # + pad + pad
    Chunk["beg"][i] =  int(y + (top[i]          * (h / dim)))  # - pad
    Chunk["end"][i] =  int(y + (bot[i]          * (h / dim)))  # - pad
  }
}

function paperpage(page    , p1, p2, i) {

  # page structure of scan
  p1[1]  = 23;
  p1[8]  ="M"; p1[9]  ="M"; p1[10]  =30
  p1[40] ="M"; p1[41] ="M"; p1[42]  =60
  p1[104]="M"; p1[105]="M"; p1[106]=122
  p1[456]=480
  for (i = 1; i <= 960 ; i++) {
    if (p1[i]) 
      p2[i] = p1[i]
    else
      p2[i] = p2[i-1] + 1
  }

  if ((page < 1) || (page > 960)) {
    print "page out of range" > "/dev/stderr"
    exit 0
  }
  else if (p2[page] == "M") {
    print "page " page " missing" > "/dev/stderr"
    exit 0
  }
  else
    return p2[page]
}

function collect (     cmd, i, j, file) {

  FS="|"
  while ((getline < "../G2F/g2f") > 0)
    g2f[$1] = $2

  cmd = "for i in `find tiff -name '*txt' | sort`; do echo '===='; "    \
    "echo $i; echo '----'; cat $i ; done"
  RS = "====\n"
  while ((cmd | getline) > 0 )
    file[++i] = $0

  if (ARGV[2] == "xml") {
    print "<hulten>"
    print "  <!-- DO NOT REMOVE THIS METADATA SECTION FROM THE XML FILE -->"
    print "  <metadata><![CDATA[\n"
    print "    Eric HultÃ©n (1968) 'Flora of Alaska and Neighboring Territories:"
    print "    A Manual of the Vascular Plants'\n"
    print "    (c) 1968 Board of Trustees of the Leland Stanford Jr. Univ.\n"
    print "    Digitized by Cam Webb <https://camwebb.info> during 2019-2021"
    print "    as part of work on a new Flora of Alaska <https://alaskaflora.org>,"
    print "    funded by the US National Science Foundation (Grant 1759964).\n"
    print "    Permission for digitization given by Stanford University Press"
    print "    in letter SUPP04133 (of 2017-04-20).\n"
    print "    Data shared under Creative Commons license BY-NC-SA 4.0 Intl."
    print "    <https://creativecommons.org/licenses/by-nc-sa/4.0/>"
    print "    Any commercial use, including reprint in other publications,"
    print "    will require prior permission from the publisher.\n"
    print "    ]]>"
    print "  </metadata>"
    print "  <date>" strftime("%Y-%m-%d") "</date>\n"
  }
  
  OFS="|"
  for (j = 2; j <= i; j++) {
    # split filename from data
    split(file[j], part, "\n----\n")
    commonname = ""
    id = part[1] ; gsub(/tiff\/[0-9]+\//,"",id); gsub(/\-t\.txt/,"",id)

    # split into (5) fields
    split(part[2],parts,/(\n *)(\n *)+/)
    # clean
    for (k in parts) gsub(/^\- *\n*$/,"", parts[k])

    # names - get common name
    cn = split(parts[1],cname, "|")
    if (cn == 2) commonname = cname[2]
    gsub(/ *$/,"",commonname);     gsub(/^ */,"",commonname);
    
    # scientific name
    split(cname[1],sname, "/")
    sname[1] = cleanname(sname[1])
    
    # print id ,                                                       \
    #   lowersecondword(sname[1]),                                     \
    #   commonname,                                                    \
    #   gensub(/\n/,"^","G",parts[2]),                                 \
    #   gensub(/\n/," ","G",parts[3]),                                 \
    #   gensub(/\n/," ","G",parts[4]),                                 \
    #   gensub(/\n/," ","G",parts[5]),                                 \
    #   gensub(/\n/," ","G",parts[6])

    for (k = 3; k <= 6; k++) {
      gsub(/\n/," ",parts[k])
      gsub(/  +/," ",parts[k])
      gsub(/^ +/,"",parts[k])
      gsub(/ +$/,"",parts[k])
    }

    if (ARGV[2] == "data") {
      print id ,  lowersecondword(sname[1]),    \
        parts[3],parts[4],parts[5],parts[6]
      continue
    }

    # process syns
    s = 0
    synprint = ""
    synxml = "    <syns>\n"
    
    nsyn = split(parts[2], syn, "\n")
    for (k = 1; k <= nsyn; k++) {
      gsub(/ *;.*$/,"", syn[k])
      gsub(/^ +/,"", syn[k])
      if (!length(syn[k]))
        continue
      s++
      if (syn[k] !~ /^[A-Z]\./) {
        abbrev[substr(syn[k],1,1)] = syn[k]
        gsub(/ .*$/,"",abbrev[substr(syn[k],1,1)])
      }
      else {
        regex = "^" substr(syn[k],1,1) "\\."
        if (!abbrev[substr(syn[k],1,1)])
          gsub(regex, ("FAIL " substr(syn[k],1,1) "."), syn[k])
          # Find with hulten2info --col | grep FAIL
        else
          gsub(regex, ("" abbrev[substr(syn[k],1,1)]), syn[k])
      }
      
      synprint = synprint id "-s" s "|"                                 \
        parse_taxon_name(lowersecondword(cleanname(syn[k])),0) "|" id "\n"
      
      synxml = synxml "      <syn id=\"" id "-s" s "\">"        \
        xmlclean(lowersecondword(cleanname(syn[k]))) "</syn>\n"
    }
    delete abbrev
    synxml = synxml "    </syns>\n"

    if (ARGV[2] == "xml") {
      
      print "  <taxon id=\"" id "\">"
      print "    <name>" xmlclean(lowersecondword(sname[1])) "</name>"
      if (length(synxml) > 23)
        printf "%s", synxml
      if (g2f[gensub(/ .*$/,"","G",sname[1])])
        print "    <fam>" g2f[gensub(/ .*$/,"","G",sname[1])] "</fam>"
      if (commonname)
        print "    <common>" xmlclean(tolower(commonname)) "</common>"
      if (parts[3])
        print "    <desc>" xmlclean(parts[3]) "</desc>"
      if (parts[4])
        print "    <ecol>" xmlclean(parts[4]) "</ecol>"
      if (parts[5])
        print "    <tax>" xmlclean(parts[5]) "</tax>"
      if (parts[6])
        print "    <use>" xmlclean(parts[6]) "</use>"

      # get longlat
      cmd = "if [ -f tiff/" gensub(/-.*$/,"","G",id) "/" id             \
        "-1.csv ] ; then cat tiff/" gensub(/-.*$/,"","G",id) "/" id     \
        "-1.csv | tr '\n' ';' ; fi;"
      longlats = ""
      cmd | getline longlats
      if (longlats) {
        printf "    <specimens>\n      "
        gsub(/^x,y;/,"",longlats)
        nll = split(longlats,longlat,";")
        for (k = 1; k < nll; k++)
          printf "<xy>%s</xy>", longlat[k]
        print "\n    </specimens>"
      }
      close(cmd)

      print "  </taxon>"
    }
    else {
      print id , parse_taxon_name(lowersecondword(sname[1]),0), "accepted"
      printf "%s", synprint
    }
    
  }

  if (ARGV[2] == "xml")
    print "</hulten>"

  
  # test with : hulten2info --col > hulten.tmp
  # grep "|subsp.||" hulten.tmp
  # and for var. , f.
  # summarize_field 2 hulten.tmp
}

function checkfields (     cmd, i, j, file) {

  cmd = "find tiff -name '*txt' | sort"
  while ((cmd | getline) > 0 )
    file[++i] = $0
  if (ARGV[2] !~ /[0-9]+/)
    exit 1
  
  for (j = 1; j <= ARGV[2]; j++) {
    RS = ""
    rec = 0
    edit = 0
    while ((getline < file[j]) > 0) {
      rec++
      # format tests
      if (((rec > 1) && ($0 ~ /[/^|]/)) ||        \
          ((rec == 1) && ($0 ~ /[0-9]/)))
        edit = 1
      if (rec == 1) {
        gsub(/[/|].*$/,"",$0)
        if ($0 ~ /^[^ ]+ [^ ]+ .+(subsp\.|var\.| f\..)/)
          edit = 1
      }

      # check synonyms
      if (rec == 2) {
        split($0, line, "\n")
        for (k in line) {
          gsub(/;.*$/,"",line[k])
          # print line[k]
          # picks up subsp. ... var. ... too
          if ((line[k] ~ /^[^ ]+ [^ ]+ .+(subsp\.|var\.| f\..)/) ||   \
              (line[k] ~ /(in part|not |Alaska|respect|authors|auct\.|ined\.|comb\. nov\.|sensu)/))
            edit = 1
        }
      }
      # forma - makes a lot
      # if (rec < 3)
      #  if ($0 ~ / f. /)
      #    edit = 1
    }
    printf "%3d  %s  %d\n", j, file[j], rec
    # rec number test
    if (rec != 6)
      edit = 1
    if (edit)
      system("emacs -nw -Q " file[j])
  }
}


function lowersecondword(x,    n, y, out, i) {
  n = split(x, y, / +/)
  out = y[1] " " tolower(y[2])
  for (i = 3; i <=n; i++) {
    if (y[i] ~ /(var\.|subsp\.)/)
      y[i+1] = tolower(y[i+1])
    out = out " " y[i]
  }
  return out
}


# ImageMagick tricks

# magick display -crop 4510x6000+0+450 -resize x1080 p26.tif

# Old method for finding whitespace, use slim bands
# for h in `seq 1000 200 5000`
# do
#   BLACK=`convert out.tif -crop 4510x10+0+$h -threshold 80%             \
#     -format %c -define histogram:unique-colors=true histogram:info:-    \
#     | gawk 'BEGIN{z=0} /#000000/ {gsub(/:/,"",$1); if ($1+0 > 100) z=1}   \
#            END{print z}'`
#     # record the first
#     if [ $BLACK -eq 0 -a $INWHITE -eq 0 ]
#     then
#         let WSTART=h
#         let INWHITE=1
#     elif [ $BLACK -eq 1 -a $INWHITE -eq 1 ]
#     then
#         let WEND=h-190
#         let INWHITE=0
#         # assume that the main break has been found and bail
#         break
#     fi
#     # echo $h $BLACK $INWHITE $WSTART $WEND 
# done
# let SPLIT=`gawk "BEGIN{print int($WSTART+(($WEND-$WSTART)/2))}"`
# echo $WSTART $WEND $SPLIT
# # now crop:
# let H2=6000-$SPLIT
# convert out.tif -crop 4510x$SPLIT+0+0 top.tif
# convert out.tif -crop 4510x$H2+0+$SPLIT bot.tif

function cleanname(name) {
  gsub(/ *$/,"",name)
  gsub(/^ */,"",name)

  # grep --color='auto' -P -n "[^\x00-\x7F]"
  # almost all Ã© were in names, not in authors, so use this: 
  gsub(/[Ã©Ã¨]/,"e",name)
  gsub(/\( +/,"(",name)

  return name
}

function xmlclean(x) {
  gsub(/</,"&lt;",x)
  gsub(/>/,"&gt;",x)
  gsub(/&/,"&amp;",x)
  return x
}
